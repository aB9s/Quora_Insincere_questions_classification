{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Created on Sat Mar  9 2019\n",
    "\n",
    "@author: aB9\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1306122, 3), (375806, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004f9a462a357c33be</td>\n",
       "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005059a06ee19e11ad</td>\n",
       "      <td>Why does Quora automatically ban conservative ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000559f875832745e2e</td>\n",
       "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005bd3426b2d0c8305</td>\n",
       "      <td>Is there such a thing as dressing moderately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00006e6928c5df60eacb</td>\n",
       "      <td>Is it just me or have you ever been in this ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "5  00004f9a462a357c33be  Is Gaza slowly becoming Auschwitz, Dachau or T...   \n",
       "6  00005059a06ee19e11ad  Why does Quora automatically ban conservative ...   \n",
       "7  0000559f875832745e2e  Is it crazy if I wash or wipe my groceries off...   \n",
       "8  00005bd3426b2d0c8305  Is there such a thing as dressing moderately, ...   \n",
       "9  00006e6928c5df60eacb  Is it just me or have you ever been in this ph...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qid', 'question_text', 'target'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000101884c19f3515c1a</td>\n",
       "      <td>How do you train a pigeon to send messages?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00010f62537781f44a47</td>\n",
       "      <td>What is the currency in Langkawi?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00012afbd27452239059</td>\n",
       "      <td>What is the future for Pandora, can the busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?\n",
       "5  000101884c19f3515c1a        How do you train a pigeon to send messages?\n",
       "6  00010f62537781f44a47                  What is the currency in Langkawi?\n",
       "7  00012afbd27452239059  What is the future for Pandora, can the busine...\n",
       "8  00014894849d00ba98a9  My voice range is A2-C5. My chest voice goes u...\n",
       "9  000156468431f09b3cae           How much does a tutor earn in Bangalore?"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qid', 'question_text'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data into train data and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data[['qid','question_text']], train_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...\n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...\n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...\n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...\n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[['qid','question_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGEXs to remove unwanted patterns from the text\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "# BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^a-zA-Z]') # for word2vec\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text, remove_stopwords = False):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    # remove HTML\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    \n",
    "    \n",
    "    #replace Symbols with a space in string\n",
    "#     text = re.sub(REPLACE_BY_SPACE_RE, \" \",text)\n",
    "    \n",
    "    \n",
    "    # delete unwanted synbols from string\n",
    "    text = re.sub(BAD_SYMBOLS_RE,\" \", text)\n",
    "    \n",
    "    # convert all characters in a string to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # delete stopwords from text\n",
    "    if remove_stopwords:\n",
    "        text = remove_stopwords(text)\n",
    "    \n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punk tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('/data/tokenizers/punkt/english.pickle')\n",
    "# C:\\Users\\abhi\\AppData\\Roaming\\nltk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to split the text into parsed sentences\n",
    "Returns a list of sentences, where each sentence is a list of words\n",
    "\"\"\"\n",
    "def text_to_senteces(text, tokenizer, remove_stopwords = False):\n",
    "    # NlTK tokenizer to split the paragtraph into sentences\n",
    "    raw_texts = tokenizer.tokenize(text.strip())\n",
    "    \n",
    "    # loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_text in raw_texts:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_text) > 0:\n",
    "            # otherwise, call text_prepare to get a list of words\n",
    "            sentences.append(text_prepare(raw_text))\n",
    "    \n",
    "    # Return the list of sentencecs (each sentence is a list of words,\n",
    "    # so this returns a list of lists)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from labeled training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:272: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.dn.se/nyheter/varlden/bannon-weve-studied-the-sweden-democrats-for-a-while/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=qtKuhKKEtw4?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.instagram.com/mi.mo.clothing/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://play.google.com/store/apps/details?id=com.Lithium.Maze\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=tpHxfFx6cyI&t=150s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=9nmvWtpXQ6g\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/Bl-WZtBfQeo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:272: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/6ss5L-oDEy0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/sOlwDL8HtT0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=HuS8Wx9JrWI\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://wp.me/p8KmP7-2I\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://m.youtube.com/watch?v=87dz8BEjgV4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.dropbox.com/s/mnpst540bvbmcy3/haku.wav?dl=0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.crystone.com/)?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://stacynewrevolution.wordpress.com/2017/06/06/search-the-internet-using-images-and-graphics/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.foxnews.com/science/2018/05/17/hawaii-volcano-explosive-eruption-at-kilaueas-summit.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://metro.co.uk/2018/03/09/mod-confirm-uk-one-step-closer-finalising-sale-48-fighter-jets-saudi-arabia-7375516/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://incredible-theme.tumblr.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://en.wikipedia.org/wiki/John_Archibald_Wheeler\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/qXDJvdN-ZMA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://s-media-cache-ak0.pinimg.com/originals/29/de/2d/29de2dbeee4e728e6364611a88458f82.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://gabrielebaldassarre.com/r/facebook/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://qr.ae/TU1PMf?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.pinterest.com/acmar13/megaman-series/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.investopedia.com/news/anonymous-cryptocurrency-enthusiast-bought-400-million-bitcoin/?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://pennymattersblog.wordpress.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.straitstimes.com/asia/australianz/for-taiwanese-tests-of-loyalty-to-china-bring-trouble-in-australian-workplaces\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=...\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.theeventchronicle.com/finanace/three-countries-left-without-rothschild-central-bank/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://charity-perks.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.thenophone.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.website.com/file.jpg)?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/_squmQKmHJo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://free.ultimaiq.net/numerus_basic.htm?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=9iG3OiAbsXg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://m.facebook.com/story.php?story_fbid=1334622193322541&id=969114406539990\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.kishanmeghwal.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://ipsc.ksp.sk/2017/real/problems/l.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.bbc.co.uk/news/health-40608253\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=vLYhdoSorIg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.quora.com/Why-dont-people-understand-Donald-Trump?share=fe457a6f&srid=p3dW4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.jpost.com/Israel-News/Culture/Japanese-PM-Abe-served-offensive-shoe-dessert-at-Netanyahu-dinner-553671#/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=4nkw0nULR6I\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.statista.com/statistics/268083/countries-with-the-lowest-fertility-rates/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://imgur.com/a/y8AvT\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:272: UserWarning: \"b'/'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://pastebin.com/zVqQ5f13\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:272: UserWarning: \"b'\\\\'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.facebook.com/DailySocial7/videos/467619073627500/?pnref=story\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=KEkrWRHCDQU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/EF7XzPOD6Mo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://imgur.com/a/02q3z\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://goo.gl/bEUhes\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://m.hindustantimes.com/mumbai-news/22-dead-35-injured-in-stampede-at-mumbai-s-elphinstone-road-station/story-oqPqfPrr7p0C9pE9W8SNPK.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=YVmIaBW-HjI\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://imgur.com/a/IPNHc8X\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://mothership.sg/2017/02/cias-failed-attempt-to-bribe-lee-kuan-yew-among-newly-released-documents/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.orionsarm.com/fm_store/Paul%20Birch%27s%20Page.htm\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://listentogrow.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://imgur.com/Tngq6Fr\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.rothschild.com/en/russia-and-the-cis/?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=n3xgjxJwedA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://fittestshop.cz/cms-shop/public/galerie-img/nike-metcon-2-training-shoes-m-barevn-819899-701-3-bjT.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.bodybuilding.com/fun/living-large-jay-cutlers-8-week-mass-building-trainer.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=s9-PXIXOHhI?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=84WIaK3bl_s&ab_channel=CaseyNeistat.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://sgman0202.quora.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://twitter.com/victoriaa_sob/status/884226922099728384\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://bit.ly/2lwuzQe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://theviralgrind.blogspot.qa/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.fiverr.com/s2/5dc16b1fdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=GpJ36KzHJG4?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/xMuUMVJaNOM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://github.com/careercup/ctc...\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://rapefilms.net/insest/2197.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.quora.com/What-is-one-word-that-keeps-you-going-in-life\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://stacynewrevolution.wordpress.com/2017/05/30/what-they-dont-want-you-to-know-about-android-7/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://bloom.bg/2oReWCt\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://goo.gl/CUYc4K\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://ifunny.co/fun/TiW9Nuxq4\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://en.wikipedia.org/wiki/Wormhole#Traversable_wormholes\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.amazon.in/dp/B076T8RD6B/ref=pe_3025041_185740121_TE_item\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=_-qlBa11FyQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.quora.com/How-do-you-fix-a-coolant-leak-in-your-car#?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://cty.jhu.edu/imagine/resources/internships/science.html?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.austinlizards.com/listen/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://nationalinterest.org/blog/the-skeptics/can-america-share-its-superpower-status-17427\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://patriottribune.com/44664/...\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://twitter.com/DerrickQLewis\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://nypost.com/2018/05/30/vitamins-are-a-massive-waste-of-money-research-shows/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.middleeastmonitor.com/20161228-explained-palestinian-citizens-of-israel/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://shop.samsung.com/in/rt28k3022se-hl.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/feed/history?query=test+hello\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://stacynewrevolution.wordpress.com/2017/06/15/the-next-future-of-mobile-artificial-intelligence/?preview=true\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/jPKARhopdqo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.dropbox.com/s/1p2qr0jzo8vq16x/Screenshot%202017-07-22%2011.53.48.png?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://i.imgur.com/cmHHpR2.jpg?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=Boe-uUQ3ttM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/ZsTsN2z5Kl4?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=0xqybhU8vEI\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.tomatobubble.com/pro_einstein_propaganda.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=Ctz_dHfYfb8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://imgur.com/a/Jyw4w\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://secure.humancoalition.org/twitter-censorship-sa/?sc=CID-12516&utm_campaign=Twitter-Censorship-Petition&utm_medium=paid&utm_source=facebook\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=UXPhLXuJ90I\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://backtocart.co/livechat/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://shoebat.com/wp-content/uploads/2016/12/ardoganki.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.nytimes.com/2018/04/13/us/politics/trump-calls-comey-untruthful-slimeball-as-book-details-released.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.teaparty.org/former-secret-service-agent-democrats-covering-biggest-scandal-modern-political-history-video-289453/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://drive.google.com/open?id=0BwmcF29pwpFOSVprRlFNUFdWanc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.facebook.com/taffofuneralservices/videos/1892373607456093/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from unlabeled set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.sgakumbakonam.in/h2o\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.cnbc.com/2018/01/18/the-dows-31-percent-gain-during-trumps-first-year-is-the-best-since-fdr.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/TMjGm6qK1So\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://en.wikipedia.org/wiki/Mason–Dixon_line\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.windows-movie-maker.org\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.teaparty.org/sedition-former-attorney-general-eric-holder-urges-doj-employees-defy-trump-administration-306088/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.shopprice.com.au?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=U1BLXQun_AU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.facebook.com/Masterpiece-Cake-Shop-116106311747019/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/26j736fbluE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=ROLiaBBdQHA?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://wrapbootstrap.com/)?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/JrAISWghbco\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://edition.cnn.com/2018/06/13/health/falling-iq-scores-study-intl/index.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=OW9MfQB7WBQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.sothebys.com/en/news-video/blogs/specials/sotheby-s-financial-services/2016/11/our-services.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://face2faceafrica.com/article/slavery-africa-today/2\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=tctl8FNasFo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.thelifeshaper.com/latest-gd-topics-ग्रुप-डिस्कशन-के-लेटेस्/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.chicagotribune.com/news/opinion/commentary/ct-perspec-hanson-mueller-mccabe-hillary-clinton-donald-trump-james-comey-huma-abedin-investigation-0430-story.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.instagram.com/p/BTNHs0TFT-A/?\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://m.youtube.com/watch?list=WL&v=Jf-re-0NjwQ.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.facebook.com/greatatal/videos/152197206786129/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.fentanesandassociates.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.raisin.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.delawareregisteredagentservice.com/free-delaware-incorporation-service.\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.everlane.com/factories/tailored-shirting\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://inews.co.uk/opinion/i-police-officer-i-want-know-manchester-attacks/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://soundingboard.earfoundation.org.uk/downloads/cochlearimplantshoppingguide.pdf\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://imgur.com/VZbqWTW\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://youtu.be/3gvC0FUNE0A\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?time_continue=128&v=j-9Js7aaeJo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://bit.ly/2pJJkyc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://millionmotivation.com/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.youtube.com/watch?v=Q7w3xCDZqdA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://www.minorityaffairs.gov.in\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://www.nytimes.com/1991/12/21/world/soviet-disarray-yeltsin-says-russia-seeks-to-join-nato.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"http://vocaroo.com/i/s12VeQcizGTc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\bs4\\__init__.py:335: UserWarning: \"https://ucr.fbi.gov/crime-in-the-u.s/2012/crime-in-the-u.s.-2012/tables/42tabledatadecoverviewpdf/table_42_arrests_by_sex_2012.xls\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list of sentences\n",
    "sentences = []\n",
    "\n",
    "print(\"Parsing sentences from labeled training set\")\n",
    "for text in X_train['question_text']:\n",
    "#     print(text)\n",
    "    sentences+= text_to_senteces(text, tokenizer)\n",
    "\n",
    "print(\"Parsing sentences from unlabeled set\")\n",
    "for text in X_test['question_text']:\n",
    "#     print(text)\n",
    "    sentences+= text_to_senteces(text, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914724\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how',\n",
       " 'did',\n",
       " 'quebec',\n",
       " 'nationalists',\n",
       " 'see',\n",
       " 'their',\n",
       " 'province',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nation',\n",
       " 'in',\n",
       " 'the',\n",
       " 's']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'mean',\n",
       " 'i',\n",
       " 'don',\n",
       " 't',\n",
       " 'think',\n",
       " 'humans',\n",
       " 'will',\n",
       " 'survive',\n",
       " 'on',\n",
       " 'this',\n",
       " 'earth',\n",
       " 'for',\n",
       " 'another',\n",
       " 'years',\n",
       " 'what',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1914723]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging module creates nice output messages\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set values for various parameters\"\"\"\n",
    "\n",
    "# Word vector dimensionality\n",
    "num_features = 300\n",
    "# Minimum word count\n",
    "min_word_count = 40\n",
    "# Number of threads to run in parallel\n",
    "num_workers = 4\n",
    "# Context window size\n",
    "context = 10\n",
    "# Downsample setting for frequent words\n",
    "downsampling = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2019-04-26 17:56:41,812 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 17:56:45,662 : INFO : collecting all words and their counts\n",
      "2019-04-26 17:56:45,663 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-04-26 17:56:45,693 : INFO : PROGRESS: at sentence #10000, processed 112571 words, keeping 13902 word types\n",
      "2019-04-26 17:56:45,724 : INFO : PROGRESS: at sentence #20000, processed 225358 words, keeping 20140 word types\n",
      "2019-04-26 17:56:45,757 : INFO : PROGRESS: at sentence #30000, processed 338365 words, keeping 24944 word types\n",
      "2019-04-26 17:56:45,783 : INFO : PROGRESS: at sentence #40000, processed 451240 words, keeping 29015 word types\n",
      "2019-04-26 17:56:45,813 : INFO : PROGRESS: at sentence #50000, processed 564335 words, keeping 32403 word types\n",
      "2019-04-26 17:56:45,843 : INFO : PROGRESS: at sentence #60000, processed 677543 words, keeping 35611 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 17:56:45,874 : INFO : PROGRESS: at sentence #70000, processed 791481 words, keeping 38555 word types\n",
      "2019-04-26 17:56:45,904 : INFO : PROGRESS: at sentence #80000, processed 905229 words, keeping 41192 word types\n",
      "2019-04-26 17:56:45,936 : INFO : PROGRESS: at sentence #90000, processed 1019487 words, keeping 43731 word types\n",
      "2019-04-26 17:56:45,968 : INFO : PROGRESS: at sentence #100000, processed 1132870 words, keeping 46116 word types\n",
      "2019-04-26 17:56:45,999 : INFO : PROGRESS: at sentence #110000, processed 1246878 words, keeping 48337 word types\n",
      "2019-04-26 17:56:46,026 : INFO : PROGRESS: at sentence #120000, processed 1359392 words, keeping 50369 word types\n",
      "2019-04-26 17:56:46,058 : INFO : PROGRESS: at sentence #130000, processed 1472178 words, keeping 52405 word types\n",
      "2019-04-26 17:56:46,090 : INFO : PROGRESS: at sentence #140000, processed 1585505 words, keeping 54401 word types\n",
      "2019-04-26 17:56:46,121 : INFO : PROGRESS: at sentence #150000, processed 1698087 words, keeping 56274 word types\n",
      "2019-04-26 17:56:46,149 : INFO : PROGRESS: at sentence #160000, processed 1812645 words, keeping 58094 word types\n",
      "2019-04-26 17:56:46,179 : INFO : PROGRESS: at sentence #170000, processed 1925360 words, keeping 59880 word types\n",
      "2019-04-26 17:56:46,210 : INFO : PROGRESS: at sentence #180000, processed 2037873 words, keeping 61589 word types\n",
      "2019-04-26 17:56:46,243 : INFO : PROGRESS: at sentence #190000, processed 2151212 words, keeping 63319 word types\n",
      "2019-04-26 17:56:46,273 : INFO : PROGRESS: at sentence #200000, processed 2263667 words, keeping 64988 word types\n",
      "2019-04-26 17:56:46,303 : INFO : PROGRESS: at sentence #210000, processed 2377091 words, keeping 66624 word types\n",
      "2019-04-26 17:56:46,335 : INFO : PROGRESS: at sentence #220000, processed 2490500 words, keeping 68144 word types\n",
      "2019-04-26 17:56:46,371 : INFO : PROGRESS: at sentence #230000, processed 2603699 words, keeping 69716 word types\n",
      "2019-04-26 17:56:46,403 : INFO : PROGRESS: at sentence #240000, processed 2717130 words, keeping 71223 word types\n",
      "2019-04-26 17:56:46,437 : INFO : PROGRESS: at sentence #250000, processed 2830192 words, keeping 72649 word types\n",
      "2019-04-26 17:56:46,471 : INFO : PROGRESS: at sentence #260000, processed 2942997 words, keeping 74097 word types\n",
      "2019-04-26 17:56:46,501 : INFO : PROGRESS: at sentence #270000, processed 3056143 words, keeping 75486 word types\n",
      "2019-04-26 17:56:46,534 : INFO : PROGRESS: at sentence #280000, processed 3168896 words, keeping 76807 word types\n",
      "2019-04-26 17:56:46,569 : INFO : PROGRESS: at sentence #290000, processed 3281184 words, keeping 78202 word types\n",
      "2019-04-26 17:56:46,603 : INFO : PROGRESS: at sentence #300000, processed 3394749 words, keeping 79507 word types\n",
      "2019-04-26 17:56:46,639 : INFO : PROGRESS: at sentence #310000, processed 3508910 words, keeping 80727 word types\n",
      "2019-04-26 17:56:46,678 : INFO : PROGRESS: at sentence #320000, processed 3622855 words, keeping 82052 word types\n",
      "2019-04-26 17:56:46,723 : INFO : PROGRESS: at sentence #330000, processed 3735466 words, keeping 83324 word types\n",
      "2019-04-26 17:56:46,756 : INFO : PROGRESS: at sentence #340000, processed 3848288 words, keeping 84602 word types\n",
      "2019-04-26 17:56:46,790 : INFO : PROGRESS: at sentence #350000, processed 3961750 words, keeping 85811 word types\n",
      "2019-04-26 17:56:46,819 : INFO : PROGRESS: at sentence #360000, processed 4075797 words, keeping 87071 word types\n",
      "2019-04-26 17:56:46,854 : INFO : PROGRESS: at sentence #370000, processed 4188794 words, keeping 88235 word types\n",
      "2019-04-26 17:56:46,889 : INFO : PROGRESS: at sentence #380000, processed 4301955 words, keeping 89390 word types\n",
      "2019-04-26 17:56:46,921 : INFO : PROGRESS: at sentence #390000, processed 4416052 words, keeping 90563 word types\n",
      "2019-04-26 17:56:46,955 : INFO : PROGRESS: at sentence #400000, processed 4529493 words, keeping 91715 word types\n",
      "2019-04-26 17:56:46,985 : INFO : PROGRESS: at sentence #410000, processed 4642279 words, keeping 92885 word types\n",
      "2019-04-26 17:56:47,017 : INFO : PROGRESS: at sentence #420000, processed 4755200 words, keeping 94005 word types\n",
      "2019-04-26 17:56:47,048 : INFO : PROGRESS: at sentence #430000, processed 4868816 words, keeping 95142 word types\n",
      "2019-04-26 17:56:47,083 : INFO : PROGRESS: at sentence #440000, processed 4982945 words, keeping 96247 word types\n",
      "2019-04-26 17:56:47,111 : INFO : PROGRESS: at sentence #450000, processed 5096643 words, keeping 97410 word types\n",
      "2019-04-26 17:56:47,141 : INFO : PROGRESS: at sentence #460000, processed 5208962 words, keeping 98457 word types\n",
      "2019-04-26 17:56:47,171 : INFO : PROGRESS: at sentence #470000, processed 5322293 words, keeping 99523 word types\n",
      "2019-04-26 17:56:47,204 : INFO : PROGRESS: at sentence #480000, processed 5435935 words, keeping 100615 word types\n",
      "2019-04-26 17:56:47,237 : INFO : PROGRESS: at sentence #490000, processed 5549537 words, keeping 101641 word types\n",
      "2019-04-26 17:56:47,271 : INFO : PROGRESS: at sentence #500000, processed 5662857 words, keeping 102666 word types\n",
      "2019-04-26 17:56:47,308 : INFO : PROGRESS: at sentence #510000, processed 5775930 words, keeping 103791 word types\n",
      "2019-04-26 17:56:47,341 : INFO : PROGRESS: at sentence #520000, processed 5889440 words, keeping 104850 word types\n",
      "2019-04-26 17:56:47,379 : INFO : PROGRESS: at sentence #530000, processed 6002051 words, keeping 105877 word types\n",
      "2019-04-26 17:56:47,416 : INFO : PROGRESS: at sentence #540000, processed 6115071 words, keeping 106886 word types\n",
      "2019-04-26 17:56:47,456 : INFO : PROGRESS: at sentence #550000, processed 6227988 words, keeping 107978 word types\n",
      "2019-04-26 17:56:47,493 : INFO : PROGRESS: at sentence #560000, processed 6340913 words, keeping 109019 word types\n",
      "2019-04-26 17:56:47,532 : INFO : PROGRESS: at sentence #570000, processed 6454049 words, keeping 109956 word types\n",
      "2019-04-26 17:56:47,565 : INFO : PROGRESS: at sentence #580000, processed 6566873 words, keeping 110946 word types\n",
      "2019-04-26 17:56:47,598 : INFO : PROGRESS: at sentence #590000, processed 6680150 words, keeping 111910 word types\n",
      "2019-04-26 17:56:47,631 : INFO : PROGRESS: at sentence #600000, processed 6793373 words, keeping 112850 word types\n",
      "2019-04-26 17:56:47,663 : INFO : PROGRESS: at sentence #610000, processed 6906876 words, keeping 113747 word types\n",
      "2019-04-26 17:56:47,692 : INFO : PROGRESS: at sentence #620000, processed 7019857 words, keeping 114692 word types\n",
      "2019-04-26 17:56:47,723 : INFO : PROGRESS: at sentence #630000, processed 7132423 words, keeping 115624 word types\n",
      "2019-04-26 17:56:47,756 : INFO : PROGRESS: at sentence #640000, processed 7244936 words, keeping 116523 word types\n",
      "2019-04-26 17:56:47,792 : INFO : PROGRESS: at sentence #650000, processed 7358433 words, keeping 117477 word types\n",
      "2019-04-26 17:56:47,823 : INFO : PROGRESS: at sentence #660000, processed 7471083 words, keeping 118342 word types\n",
      "2019-04-26 17:56:47,855 : INFO : PROGRESS: at sentence #670000, processed 7584724 words, keeping 119227 word types\n",
      "2019-04-26 17:56:47,883 : INFO : PROGRESS: at sentence #680000, processed 7698869 words, keeping 120113 word types\n",
      "2019-04-26 17:56:47,914 : INFO : PROGRESS: at sentence #690000, processed 7813220 words, keeping 121038 word types\n",
      "2019-04-26 17:56:47,943 : INFO : PROGRESS: at sentence #700000, processed 7926655 words, keeping 121897 word types\n",
      "2019-04-26 17:56:47,973 : INFO : PROGRESS: at sentence #710000, processed 8040340 words, keeping 122795 word types\n",
      "2019-04-26 17:56:48,004 : INFO : PROGRESS: at sentence #720000, processed 8154111 words, keeping 123698 word types\n",
      "2019-04-26 17:56:48,033 : INFO : PROGRESS: at sentence #730000, processed 8267380 words, keeping 124593 word types\n",
      "2019-04-26 17:56:48,065 : INFO : PROGRESS: at sentence #740000, processed 8381127 words, keeping 125462 word types\n",
      "2019-04-26 17:56:48,093 : INFO : PROGRESS: at sentence #750000, processed 8494650 words, keeping 126302 word types\n",
      "2019-04-26 17:56:48,122 : INFO : PROGRESS: at sentence #760000, processed 8608327 words, keeping 127106 word types\n",
      "2019-04-26 17:56:48,151 : INFO : PROGRESS: at sentence #770000, processed 8721098 words, keeping 127936 word types\n",
      "2019-04-26 17:56:48,183 : INFO : PROGRESS: at sentence #780000, processed 8833837 words, keeping 128797 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 17:56:48,211 : INFO : PROGRESS: at sentence #790000, processed 8947307 words, keeping 129628 word types\n",
      "2019-04-26 17:56:48,244 : INFO : PROGRESS: at sentence #800000, processed 9059987 words, keeping 130466 word types\n",
      "2019-04-26 17:56:48,273 : INFO : PROGRESS: at sentence #810000, processed 9172498 words, keeping 131246 word types\n",
      "2019-04-26 17:56:48,303 : INFO : PROGRESS: at sentence #820000, processed 9285904 words, keeping 132073 word types\n",
      "2019-04-26 17:56:48,333 : INFO : PROGRESS: at sentence #830000, processed 9398907 words, keeping 132852 word types\n",
      "2019-04-26 17:56:48,364 : INFO : PROGRESS: at sentence #840000, processed 9512658 words, keeping 133663 word types\n",
      "2019-04-26 17:56:48,397 : INFO : PROGRESS: at sentence #850000, processed 9624914 words, keeping 134487 word types\n",
      "2019-04-26 17:56:48,427 : INFO : PROGRESS: at sentence #860000, processed 9738467 words, keeping 135317 word types\n",
      "2019-04-26 17:56:48,459 : INFO : PROGRESS: at sentence #870000, processed 9852008 words, keeping 136133 word types\n",
      "2019-04-26 17:56:48,488 : INFO : PROGRESS: at sentence #880000, processed 9965427 words, keeping 136898 word types\n",
      "2019-04-26 17:56:48,516 : INFO : PROGRESS: at sentence #890000, processed 10077674 words, keeping 137668 word types\n",
      "2019-04-26 17:56:48,554 : INFO : PROGRESS: at sentence #900000, processed 10190954 words, keeping 138468 word types\n",
      "2019-04-26 17:56:48,584 : INFO : PROGRESS: at sentence #910000, processed 10303716 words, keeping 139260 word types\n",
      "2019-04-26 17:56:48,612 : INFO : PROGRESS: at sentence #920000, processed 10416980 words, keeping 140003 word types\n",
      "2019-04-26 17:56:48,640 : INFO : PROGRESS: at sentence #930000, processed 10530896 words, keeping 140738 word types\n",
      "2019-04-26 17:56:48,668 : INFO : PROGRESS: at sentence #940000, processed 10644249 words, keeping 141473 word types\n",
      "2019-04-26 17:56:48,698 : INFO : PROGRESS: at sentence #950000, processed 10756966 words, keeping 142226 word types\n",
      "2019-04-26 17:56:48,727 : INFO : PROGRESS: at sentence #960000, processed 10870231 words, keeping 142977 word types\n",
      "2019-04-26 17:56:48,754 : INFO : PROGRESS: at sentence #970000, processed 10983166 words, keeping 143721 word types\n",
      "2019-04-26 17:56:48,782 : INFO : PROGRESS: at sentence #980000, processed 11096359 words, keeping 144505 word types\n",
      "2019-04-26 17:56:48,811 : INFO : PROGRESS: at sentence #990000, processed 11209308 words, keeping 145177 word types\n",
      "2019-04-26 17:56:48,842 : INFO : PROGRESS: at sentence #1000000, processed 11322922 words, keeping 145944 word types\n",
      "2019-04-26 17:56:48,873 : INFO : PROGRESS: at sentence #1010000, processed 11436053 words, keeping 146664 word types\n",
      "2019-04-26 17:56:48,900 : INFO : PROGRESS: at sentence #1020000, processed 11548562 words, keeping 147385 word types\n",
      "2019-04-26 17:56:48,931 : INFO : PROGRESS: at sentence #1030000, processed 11662336 words, keeping 148095 word types\n",
      "2019-04-26 17:56:48,959 : INFO : PROGRESS: at sentence #1040000, processed 11775360 words, keeping 148835 word types\n",
      "2019-04-26 17:56:48,986 : INFO : PROGRESS: at sentence #1050000, processed 11888201 words, keeping 149581 word types\n",
      "2019-04-26 17:56:49,015 : INFO : PROGRESS: at sentence #1060000, processed 12001129 words, keeping 150294 word types\n",
      "2019-04-26 17:56:49,043 : INFO : PROGRESS: at sentence #1070000, processed 12114897 words, keeping 150940 word types\n",
      "2019-04-26 17:56:49,073 : INFO : PROGRESS: at sentence #1080000, processed 12228373 words, keeping 151654 word types\n",
      "2019-04-26 17:56:49,100 : INFO : PROGRESS: at sentence #1090000, processed 12342076 words, keeping 152373 word types\n",
      "2019-04-26 17:56:49,130 : INFO : PROGRESS: at sentence #1100000, processed 12455515 words, keeping 153066 word types\n",
      "2019-04-26 17:56:49,158 : INFO : PROGRESS: at sentence #1110000, processed 12568392 words, keeping 153741 word types\n",
      "2019-04-26 17:56:49,188 : INFO : PROGRESS: at sentence #1120000, processed 12682694 words, keeping 154458 word types\n",
      "2019-04-26 17:56:49,215 : INFO : PROGRESS: at sentence #1130000, processed 12795521 words, keeping 155215 word types\n",
      "2019-04-26 17:56:49,246 : INFO : PROGRESS: at sentence #1140000, processed 12909600 words, keeping 155927 word types\n",
      "2019-04-26 17:56:49,276 : INFO : PROGRESS: at sentence #1150000, processed 13022944 words, keeping 156684 word types\n",
      "2019-04-26 17:56:49,306 : INFO : PROGRESS: at sentence #1160000, processed 13136930 words, keeping 157388 word types\n",
      "2019-04-26 17:56:49,333 : INFO : PROGRESS: at sentence #1170000, processed 13250290 words, keeping 158078 word types\n",
      "2019-04-26 17:56:49,364 : INFO : PROGRESS: at sentence #1180000, processed 13363103 words, keeping 158772 word types\n",
      "2019-04-26 17:56:49,392 : INFO : PROGRESS: at sentence #1190000, processed 13476964 words, keeping 159420 word types\n",
      "2019-04-26 17:56:49,424 : INFO : PROGRESS: at sentence #1200000, processed 13589012 words, keeping 160119 word types\n",
      "2019-04-26 17:56:49,452 : INFO : PROGRESS: at sentence #1210000, processed 13701593 words, keeping 160760 word types\n",
      "2019-04-26 17:56:49,485 : INFO : PROGRESS: at sentence #1220000, processed 13814942 words, keeping 161445 word types\n",
      "2019-04-26 17:56:49,515 : INFO : PROGRESS: at sentence #1230000, processed 13929335 words, keeping 162122 word types\n",
      "2019-04-26 17:56:49,546 : INFO : PROGRESS: at sentence #1240000, processed 14043144 words, keeping 162742 word types\n",
      "2019-04-26 17:56:49,578 : INFO : PROGRESS: at sentence #1250000, processed 14155749 words, keeping 163426 word types\n",
      "2019-04-26 17:56:49,613 : INFO : PROGRESS: at sentence #1260000, processed 14269883 words, keeping 164121 word types\n",
      "2019-04-26 17:56:49,641 : INFO : PROGRESS: at sentence #1270000, processed 14382915 words, keeping 164848 word types\n",
      "2019-04-26 17:56:49,669 : INFO : PROGRESS: at sentence #1280000, processed 14495852 words, keeping 165533 word types\n",
      "2019-04-26 17:56:49,700 : INFO : PROGRESS: at sentence #1290000, processed 14608673 words, keeping 166221 word types\n",
      "2019-04-26 17:56:49,733 : INFO : PROGRESS: at sentence #1300000, processed 14721533 words, keeping 166914 word types\n",
      "2019-04-26 17:56:49,763 : INFO : PROGRESS: at sentence #1310000, processed 14835267 words, keeping 167604 word types\n",
      "2019-04-26 17:56:49,796 : INFO : PROGRESS: at sentence #1320000, processed 14948865 words, keeping 168203 word types\n",
      "2019-04-26 17:56:49,832 : INFO : PROGRESS: at sentence #1330000, processed 15061851 words, keeping 168877 word types\n",
      "2019-04-26 17:56:49,867 : INFO : PROGRESS: at sentence #1340000, processed 15174697 words, keeping 169530 word types\n",
      "2019-04-26 17:56:49,905 : INFO : PROGRESS: at sentence #1350000, processed 15288517 words, keeping 170130 word types\n",
      "2019-04-26 17:56:49,939 : INFO : PROGRESS: at sentence #1360000, processed 15401007 words, keeping 170779 word types\n",
      "2019-04-26 17:56:49,979 : INFO : PROGRESS: at sentence #1370000, processed 15514527 words, keeping 171417 word types\n",
      "2019-04-26 17:56:50,013 : INFO : PROGRESS: at sentence #1380000, processed 15627752 words, keeping 172020 word types\n",
      "2019-04-26 17:56:50,051 : INFO : PROGRESS: at sentence #1390000, processed 15741596 words, keeping 172639 word types\n",
      "2019-04-26 17:56:50,084 : INFO : PROGRESS: at sentence #1400000, processed 15854097 words, keeping 173308 word types\n",
      "2019-04-26 17:56:50,112 : INFO : PROGRESS: at sentence #1410000, processed 15968102 words, keeping 173922 word types\n",
      "2019-04-26 17:56:50,144 : INFO : PROGRESS: at sentence #1420000, processed 16081594 words, keeping 174558 word types\n",
      "2019-04-26 17:56:50,183 : INFO : PROGRESS: at sentence #1430000, processed 16194350 words, keeping 175214 word types\n",
      "2019-04-26 17:56:50,214 : INFO : PROGRESS: at sentence #1440000, processed 16307788 words, keeping 175878 word types\n",
      "2019-04-26 17:56:50,254 : INFO : PROGRESS: at sentence #1450000, processed 16421433 words, keeping 176542 word types\n",
      "2019-04-26 17:56:50,287 : INFO : PROGRESS: at sentence #1460000, processed 16535032 words, keeping 177236 word types\n",
      "2019-04-26 17:56:50,322 : INFO : PROGRESS: at sentence #1470000, processed 16647631 words, keeping 177838 word types\n",
      "2019-04-26 17:56:50,363 : INFO : PROGRESS: at sentence #1480000, processed 16760906 words, keeping 178459 word types\n",
      "2019-04-26 17:56:50,397 : INFO : PROGRESS: at sentence #1490000, processed 16873619 words, keeping 179013 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 17:56:50,435 : INFO : PROGRESS: at sentence #1500000, processed 16987805 words, keeping 179656 word types\n",
      "2019-04-26 17:56:50,467 : INFO : PROGRESS: at sentence #1510000, processed 17102047 words, keeping 180294 word types\n",
      "2019-04-26 17:56:50,503 : INFO : PROGRESS: at sentence #1520000, processed 17215026 words, keeping 180899 word types\n",
      "2019-04-26 17:56:50,535 : INFO : PROGRESS: at sentence #1530000, processed 17327051 words, keeping 181499 word types\n",
      "2019-04-26 17:56:50,567 : INFO : PROGRESS: at sentence #1540000, processed 17440937 words, keeping 182134 word types\n",
      "2019-04-26 17:56:50,597 : INFO : PROGRESS: at sentence #1550000, processed 17554401 words, keeping 182785 word types\n",
      "2019-04-26 17:56:50,633 : INFO : PROGRESS: at sentence #1560000, processed 17668285 words, keeping 183419 word types\n",
      "2019-04-26 17:56:50,664 : INFO : PROGRESS: at sentence #1570000, processed 17782336 words, keeping 184023 word types\n",
      "2019-04-26 17:56:50,694 : INFO : PROGRESS: at sentence #1580000, processed 17895116 words, keeping 184614 word types\n",
      "2019-04-26 17:56:50,726 : INFO : PROGRESS: at sentence #1590000, processed 18009268 words, keeping 185234 word types\n",
      "2019-04-26 17:56:50,753 : INFO : PROGRESS: at sentence #1600000, processed 18121817 words, keeping 185788 word types\n",
      "2019-04-26 17:56:50,783 : INFO : PROGRESS: at sentence #1610000, processed 18235509 words, keeping 186417 word types\n",
      "2019-04-26 17:56:50,814 : INFO : PROGRESS: at sentence #1620000, processed 18348938 words, keeping 186974 word types\n",
      "2019-04-26 17:56:50,844 : INFO : PROGRESS: at sentence #1630000, processed 18462925 words, keeping 187569 word types\n",
      "2019-04-26 17:56:50,874 : INFO : PROGRESS: at sentence #1640000, processed 18576224 words, keeping 188128 word types\n",
      "2019-04-26 17:56:50,904 : INFO : PROGRESS: at sentence #1650000, processed 18689681 words, keeping 188716 word types\n",
      "2019-04-26 17:56:50,937 : INFO : PROGRESS: at sentence #1660000, processed 18803357 words, keeping 189291 word types\n",
      "2019-04-26 17:56:50,964 : INFO : PROGRESS: at sentence #1670000, processed 18916815 words, keeping 189881 word types\n",
      "2019-04-26 17:56:50,994 : INFO : PROGRESS: at sentence #1680000, processed 19030192 words, keeping 190463 word types\n",
      "2019-04-26 17:56:51,026 : INFO : PROGRESS: at sentence #1690000, processed 19142597 words, keeping 191055 word types\n",
      "2019-04-26 17:56:51,054 : INFO : PROGRESS: at sentence #1700000, processed 19255712 words, keeping 191620 word types\n",
      "2019-04-26 17:56:51,087 : INFO : PROGRESS: at sentence #1710000, processed 19369737 words, keeping 192262 word types\n",
      "2019-04-26 17:56:51,115 : INFO : PROGRESS: at sentence #1720000, processed 19482165 words, keeping 192881 word types\n",
      "2019-04-26 17:56:51,146 : INFO : PROGRESS: at sentence #1730000, processed 19595873 words, keeping 193511 word types\n",
      "2019-04-26 17:56:51,176 : INFO : PROGRESS: at sentence #1740000, processed 19708556 words, keeping 194091 word types\n",
      "2019-04-26 17:56:51,205 : INFO : PROGRESS: at sentence #1750000, processed 19821769 words, keeping 194665 word types\n",
      "2019-04-26 17:56:51,233 : INFO : PROGRESS: at sentence #1760000, processed 19935093 words, keeping 195317 word types\n",
      "2019-04-26 17:56:51,264 : INFO : PROGRESS: at sentence #1770000, processed 20048954 words, keeping 195889 word types\n",
      "2019-04-26 17:56:51,294 : INFO : PROGRESS: at sentence #1780000, processed 20162054 words, keeping 196427 word types\n",
      "2019-04-26 17:56:51,325 : INFO : PROGRESS: at sentence #1790000, processed 20275275 words, keeping 197025 word types\n",
      "2019-04-26 17:56:51,355 : INFO : PROGRESS: at sentence #1800000, processed 20387598 words, keeping 197591 word types\n",
      "2019-04-26 17:56:51,383 : INFO : PROGRESS: at sentence #1810000, processed 20500990 words, keeping 198153 word types\n",
      "2019-04-26 17:56:51,416 : INFO : PROGRESS: at sentence #1820000, processed 20614612 words, keeping 198756 word types\n",
      "2019-04-26 17:56:51,452 : INFO : PROGRESS: at sentence #1830000, processed 20728447 words, keeping 199325 word types\n",
      "2019-04-26 17:56:51,489 : INFO : PROGRESS: at sentence #1840000, processed 20842429 words, keeping 199900 word types\n",
      "2019-04-26 17:56:51,529 : INFO : PROGRESS: at sentence #1850000, processed 20956267 words, keeping 200426 word types\n",
      "2019-04-26 17:56:51,564 : INFO : PROGRESS: at sentence #1860000, processed 21069248 words, keeping 200980 word types\n",
      "2019-04-26 17:56:51,601 : INFO : PROGRESS: at sentence #1870000, processed 21182289 words, keeping 201554 word types\n",
      "2019-04-26 17:56:51,633 : INFO : PROGRESS: at sentence #1880000, processed 21296102 words, keeping 202120 word types\n",
      "2019-04-26 17:56:51,667 : INFO : PROGRESS: at sentence #1890000, processed 21409032 words, keeping 202711 word types\n",
      "2019-04-26 17:56:51,699 : INFO : PROGRESS: at sentence #1900000, processed 21521972 words, keeping 203260 word types\n",
      "2019-04-26 17:56:51,730 : INFO : PROGRESS: at sentence #1910000, processed 21635275 words, keeping 203788 word types\n",
      "2019-04-26 17:56:51,744 : INFO : collected 204040 word types from a corpus of 21688702 raw words and 1914724 sentences\n",
      "2019-04-26 17:56:51,745 : INFO : Loading a fresh vocabulary\n",
      "2019-04-26 17:56:51,847 : INFO : min_count=40 retains 18154 unique words (8% of original 204040, drops 185886)\n",
      "2019-04-26 17:56:51,847 : INFO : min_count=40 leaves 20970348 word corpus (96% of original 21688702, drops 718354)\n",
      "2019-04-26 17:56:51,907 : INFO : deleting the raw counts dictionary of 204040 items\n",
      "2019-04-26 17:56:51,914 : INFO : sample=0.0001 downsamples 383 most-common words\n",
      "2019-04-26 17:56:51,915 : INFO : downsampling leaves estimated 10180133 word corpus (48.5% of prior 20970348)\n",
      "2019-04-26 17:56:51,975 : INFO : estimated required memory for 18154 words and 300 dimensions: 52646600 bytes\n",
      "2019-04-26 17:56:51,976 : INFO : resetting layer weights\n",
      "2019-04-26 17:56:52,284 : INFO : training model with 4 workers on 18154 vocabulary and 300 features, using sg=0 hs=0 sample=0.0001 negative=5 window=10\n",
      "2019-04-26 17:56:53,300 : INFO : EPOCH 1 - PROGRESS: at 7.10% examples, 720067 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:56:54,302 : INFO : EPOCH 1 - PROGRESS: at 14.53% examples, 737145 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:56:55,305 : INFO : EPOCH 1 - PROGRESS: at 21.85% examples, 739367 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:56:56,313 : INFO : EPOCH 1 - PROGRESS: at 28.48% examples, 721832 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:56:57,320 : INFO : EPOCH 1 - PROGRESS: at 35.59% examples, 720981 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:56:58,321 : INFO : EPOCH 1 - PROGRESS: at 42.54% examples, 718654 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:56:59,325 : INFO : EPOCH 1 - PROGRESS: at 49.64% examples, 718817 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:00,329 : INFO : EPOCH 1 - PROGRESS: at 56.79% examples, 719422 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:01,345 : INFO : EPOCH 1 - PROGRESS: at 63.15% examples, 710234 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-26 17:57:02,347 : INFO : EPOCH 1 - PROGRESS: at 69.87% examples, 707510 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:03,349 : INFO : EPOCH 1 - PROGRESS: at 76.83% examples, 707478 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:04,356 : INFO : EPOCH 1 - PROGRESS: at 83.36% examples, 703599 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:05,364 : INFO : EPOCH 1 - PROGRESS: at 90.31% examples, 703538 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-26 17:57:06,369 : INFO : EPOCH 1 - PROGRESS: at 97.54% examples, 705565 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:06,700 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 17:57:06,705 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 17:57:06,707 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 17:57:06,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 17:57:06,714 : INFO : EPOCH - 1 : training on 21688702 raw words (10177986 effective words) took 14.4s, 705984 effective words/s\n",
      "2019-04-26 17:57:07,787 : INFO : EPOCH 2 - PROGRESS: at 7.42% examples, 751626 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:08,809 : INFO : EPOCH 2 - PROGRESS: at 14.85% examples, 745263 words/s, in_qsize 8, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 17:57:09,819 : INFO : EPOCH 2 - PROGRESS: at 21.66% examples, 726252 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:10,826 : INFO : EPOCH 2 - PROGRESS: at 29.22% examples, 735421 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:11,829 : INFO : EPOCH 2 - PROGRESS: at 35.54% examples, 716624 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:12,833 : INFO : EPOCH 2 - PROGRESS: at 41.80% examples, 703285 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:13,833 : INFO : EPOCH 2 - PROGRESS: at 47.80% examples, 689993 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:14,837 : INFO : EPOCH 2 - PROGRESS: at 54.39% examples, 687249 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:15,841 : INFO : EPOCH 2 - PROGRESS: at 60.79% examples, 683110 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:16,842 : INFO : EPOCH 2 - PROGRESS: at 67.89% examples, 686926 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-26 17:57:17,844 : INFO : EPOCH 2 - PROGRESS: at 74.52% examples, 685829 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:18,851 : INFO : EPOCH 2 - PROGRESS: at 81.98% examples, 691481 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:19,858 : INFO : EPOCH 2 - PROGRESS: at 89.34% examples, 695771 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:20,858 : INFO : EPOCH 2 - PROGRESS: at 96.80% examples, 700271 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:21,288 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 17:57:21,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 17:57:21,293 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 17:57:21,297 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 17:57:21,299 : INFO : EPOCH - 2 : training on 21688702 raw words (10182506 effective words) took 14.5s, 701435 effective words/s\n",
      "2019-04-26 17:57:22,314 : INFO : EPOCH 3 - PROGRESS: at 7.37% examples, 747524 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:23,321 : INFO : EPOCH 3 - PROGRESS: at 14.25% examples, 720513 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:24,329 : INFO : EPOCH 3 - PROGRESS: at 21.16% examples, 713125 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:25,334 : INFO : EPOCH 3 - PROGRESS: at 27.51% examples, 695712 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-26 17:57:26,335 : INFO : EPOCH 3 - PROGRESS: at 34.72% examples, 702791 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:27,348 : INFO : EPOCH 3 - PROGRESS: at 42.08% examples, 709207 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-26 17:57:28,349 : INFO : EPOCH 3 - PROGRESS: at 49.41% examples, 714298 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:29,349 : INFO : EPOCH 3 - PROGRESS: at 56.37% examples, 713537 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:30,350 : INFO : EPOCH 3 - PROGRESS: at 63.33% examples, 712886 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:31,356 : INFO : EPOCH 3 - PROGRESS: at 70.28% examples, 712007 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:32,360 : INFO : EPOCH 3 - PROGRESS: at 76.41% examples, 703738 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:33,362 : INFO : EPOCH 3 - PROGRESS: at 82.62% examples, 697796 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:34,364 : INFO : EPOCH 3 - PROGRESS: at 89.44% examples, 697484 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:35,368 : INFO : EPOCH 3 - PROGRESS: at 95.98% examples, 694949 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:35,906 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 17:57:35,913 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 17:57:35,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 17:57:35,923 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 17:57:35,924 : INFO : EPOCH - 3 : training on 21688702 raw words (10179251 effective words) took 14.6s, 696498 effective words/s\n",
      "2019-04-26 17:57:36,942 : INFO : EPOCH 4 - PROGRESS: at 6.91% examples, 700156 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:37,946 : INFO : EPOCH 4 - PROGRESS: at 14.39% examples, 728307 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:38,948 : INFO : EPOCH 4 - PROGRESS: at 21.53% examples, 727386 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:39,953 : INFO : EPOCH 4 - PROGRESS: at 28.53% examples, 723048 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:40,957 : INFO : EPOCH 4 - PROGRESS: at 35.95% examples, 728806 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:41,963 : INFO : EPOCH 4 - PROGRESS: at 43.14% examples, 728531 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:42,967 : INFO : EPOCH 4 - PROGRESS: at 50.57% examples, 731934 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:43,971 : INFO : EPOCH 4 - PROGRESS: at 57.34% examples, 726158 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:44,973 : INFO : EPOCH 4 - PROGRESS: at 64.70% examples, 728704 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:45,973 : INFO : EPOCH 4 - PROGRESS: at 71.67% examples, 726604 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:46,981 : INFO : EPOCH 4 - PROGRESS: at 78.94% examples, 727463 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-26 17:57:47,981 : INFO : EPOCH 4 - PROGRESS: at 86.58% examples, 731703 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:48,984 : INFO : EPOCH 4 - PROGRESS: at 93.87% examples, 732230 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:49,815 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 17:57:49,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 17:57:49,821 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 17:57:49,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 17:57:49,827 : INFO : EPOCH - 4 : training on 21688702 raw words (10179473 effective words) took 13.9s, 732850 effective words/s\n",
      "2019-04-26 17:57:50,843 : INFO : EPOCH 5 - PROGRESS: at 6.82% examples, 691608 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-26 17:57:51,849 : INFO : EPOCH 5 - PROGRESS: at 13.37% examples, 677289 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:52,854 : INFO : EPOCH 5 - PROGRESS: at 20.51% examples, 692677 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:53,854 : INFO : EPOCH 5 - PROGRESS: at 27.23% examples, 690581 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:54,860 : INFO : EPOCH 5 - PROGRESS: at 34.21% examples, 693474 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:55,872 : INFO : EPOCH 5 - PROGRESS: at 41.57% examples, 701411 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:56,872 : INFO : EPOCH 5 - PROGRESS: at 48.90% examples, 707749 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:57,876 : INFO : EPOCH 5 - PROGRESS: at 56.47% examples, 715103 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:58,879 : INFO : EPOCH 5 - PROGRESS: at 63.37% examples, 713572 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:57:59,881 : INFO : EPOCH 5 - PROGRESS: at 70.70% examples, 716629 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:58:00,883 : INFO : EPOCH 5 - PROGRESS: at 78.21% examples, 720786 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:58:01,889 : INFO : EPOCH 5 - PROGRESS: at 85.84% examples, 725327 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-26 17:58:02,893 : INFO : EPOCH 5 - PROGRESS: at 93.22% examples, 726943 words/s, in_qsize 6, out_qsize 1\n",
      "2019-04-26 17:58:03,776 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-26 17:58:03,778 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-26 17:58:03,781 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-26 17:58:03,788 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-26 17:58:03,790 : INFO : EPOCH - 5 : training on 21688702 raw words (10180214 effective words) took 14.0s, 729756 effective words/s\n",
      "2019-04-26 17:58:03,791 : INFO : training on a 108443510 raw words (50899430 effective words) took 71.5s, 711814 effective words/s\n",
      "2019-04-26 17:58:03,793 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "model_word2vec = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model_word2vec.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_word2vec.train(sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 17:58:04,023 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2019-04-26 17:58:04,024 : INFO : not storing attribute vectors_norm\n",
      "2019-04-26 17:58:04,025 : INFO : not storing attribute cum_table\n",
      "2019-04-26 17:58:05,017 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model_word2vec.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18154"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_word2vec.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhi\\Anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'none'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.doesnt_match(\"cricket football swimming tennis none\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bangladesh', 0.7272980213165283),\n",
       " ('nepal', 0.7265176773071289),\n",
       " ('kerala', 0.6324079036712646),\n",
       " ('indian', 0.6255563497543335),\n",
       " ('malaysia', 0.6192783117294312),\n",
       " ('punjab', 0.6165116429328918),\n",
       " ('pakistan', 0.6109528541564941),\n",
       " ('gujarat', 0.6100716590881348),\n",
       " ('bihar', 0.6086043119430542),\n",
       " ('karachi', 0.600983738899231)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv.most_similar(\"india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7190712690353394),\n",
       " ('guy', 0.6376925706863403),\n",
       " ('men', 0.6064354181289673),\n",
       " ('lady', 0.558889627456665),\n",
       " ('boy', 0.5585207939147949),\n",
       " ('person', 0.5341476202011108),\n",
       " ('husband', 0.5148203372955322),\n",
       " ('wife', 0.49383699893951416),\n",
       " ('girl', 0.492467999458313),\n",
       " ('whore', 0.48396003246307373)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec.wv.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
